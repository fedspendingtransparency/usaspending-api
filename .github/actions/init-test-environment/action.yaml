name: Initialize Test Environment

inputs:
  is_integration_test:
    required: true
    type: boolean
  is_spark_test:
    required: true
    type: boolean
  working_directory:
    type: string
    default: ""


runs:
  using: composite
  steps:
    - name: Set combined ENV
      shell: bash
      run: |
        echo "DATA_BROKER_DATABASE_URL=postgres://$BROKER_DB_USER:$BROKER_DB_PASSWORD@$BROKER_DB_HOST:$BROKER_DB_PORT/$BROKER_DB_NAME" >> $GITHUB_ENV
        echo "DATABASE_URL=postgres://$USASPENDING_DB_USER:$USASPENDING_DB_PASSWORD@$USASPENDING_DB_HOST:$USASPENDING_DB_PORT/$USASPENDING_DB_NAME" >> $GITHUB_ENV
        echo "DOWNLOAD_DATABASE_URL=postgres://$USASPENDING_DB_USER:$USASPENDING_DB_PASSWORD@$USASPENDING_DB_HOST:$USASPENDING_DB_PORT/$USASPENDING_DB_NAME" >> $GITHUB_ENV
        echo "ES_HOSTNAME=$ES_SCHEME://$ES_HOST:$ES_PORT" >> $GITHUB_ENV
        echo "MINIO_DATA_DIR=$HOME/Development/data/usaspending/docker/usaspending-s3" >> $GITHUB_ENV

    - name: Create directories needed for Minio and Jars
      if: ${{ inputs.is_spark_test == 'true' }}
      shell: bash
      run: |
        mkdir -p "$MINIO_DATA_DIR"
        mkdir -p "$HOME/.ivy2"

    - name: Build docker containers for DB, ES, and Minio
      working-directory: ${{ inputs.working_directory }}
      if: ${{ inputs.is_integration_test == 'true' }}
      shell: bash
      run: |
        make docker-compose-up-usaspending args="-d usaspending-db usaspending-es"
        make docker-compose-up-s3 args="-d"
    
    - name: Download broker docker image
      if: ${{ inputs.is_integration_test == 'true' }}
      uses: actions/download-artifact@v4
      with:
        name: dataact-broker-backend
        path: /tmp
    
    - name: Load broker docker image
      shell: bash
      if: ${{ inputs.is_integration_test == 'true' }}
      run: docker load --input /tmp/dataact-broker-backend.tar

    - name: Wait on DB and ES containers to be available
      if: ${{ inputs.is_integration_test == 'true' }}
      shell: bash
      run: |
        ttl=30; echo "Try DB conn from container for $ttl seconds"; until [ $ttl -le 0 ] || psql $DATABASE_URL -c 'select 1 where 1=1'; do echo $ttl; ((ttl--)); sleep 1; done; [ $ttl -gt 0 ]
        ttl=30; echo "Try ES conn from container for $ttl seconds"; until [ $ttl -le 0 ] || curl --silent -XGET --fail $ES_HOSTNAME; do echo $ttl; ((ttl--)); sleep 1; done; [ $ttl -gt 0 ]

    - name: Add DB users and set search_path
      if: ${{ inputs.is_integration_test == 'true' }}
      shell: bash
      run: |
        psql $DATABASE_URL -c "ALTER USER $USASPENDING_DB_USER SET search_path TO public,raw,int,temp,rpt"
        psql $DATABASE_URL -c "CREATE USER $BROKER_DB_USER PASSWORD '$BROKER_DB_PASSWORD' SUPERUSER"
        psql $DATABASE_URL -c "CREATE ROLE readonly"
        psql $DATABASE_URL -c "SELECT 'GRANT USAGE ON SCHEMA ' || nspname || ' TO readonly' FROM pg_namespace WHERE nspname IN ('raw','int','rpt','temp','public')"
        psql $DATABASE_URL -c "SELECT 'GRANT SELECT ON ALL TABLES IN SCHEMA ' || nspname || ' TO readonly' FROM pg_namespace WHERE nspname IN ('raw','int','rpt','temp','public')"
        psql $DATABASE_URL -c "SELECT 'ALTER DEFAULT PRIVILEGES IN SCHEMA ' || nspname || ' GRANT SELECT ON TABLES TO readonly' FROM pg_namespace WHERE nspname IN ('raw','int','rpt','temp','public')"

    - name: Run initial test to trigger DB creation
      if: ${{ inputs.is_integration_test == 'true' }}
      working-directory: ${{ inputs.working_directory }}
      shell: bash
      run: >
        pytest --create-db --numprocesses logical --no-cov --disable-warnings -r=fEs --verbosity=3 --capture=no --log-cli-level=WARNING --show-capture=log
        2> /dev/null "usaspending_api/tests/integration/test_setup_of_test_dbs.py::test_trigger_test_db_setup"

    - name: Run initial test to trigger JAR download
      if: ${{ inputs.is_spark_test == 'true' }}
      working-directory: ${{ inputs.working_directory }}
      shell: bash
      run: >
        pytest --reuse-db --numprocesses logical --no-cov --disable-warnings -r=fEs --verbosity=3
        "usaspending_api/tests/integration/test_setup_of_spark_dependencies.py::test_preload_spark_jars"
